{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networking with Python\n",
    "## Transport Control Protocol (TCP)\n",
    "### Sockets\n",
    "In computer networking, an Internet socket or network socket is a endpoint of a bidirectional inter-process communication flow across an Internet Protocol-based computer network, such as the Internet\n",
    "### Port Numbers\n",
    "A port is an application-specific or process-specific sofware communicatins endpoint, it allows multiple networked applications to coexist on the same server.\n",
    "\n",
    "There is a list of well-known TCP port numbers\n",
    "\n",
    "![ports](images/tcp_ports.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sokets in Python\n",
    "Python has built-in support for TCP Sockets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "import socket\n",
    "# Socket object\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "# conect (host, port)\n",
    "mysock.connect( ('data.pr4e.org', 80) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application Protocols\n",
    "\n",
    "### HTTP - Hypertext Transfer Protocol\n",
    "* Dominant application layer protocol on the internet\n",
    "* Invented for the web -to retirce HTML, images, documents, etc\n",
    "* Exteded to be data in addition to documents -RSS, Web services, etx. Basic concept - Make a connection - quest a document - retrieve the document - close the conection\n",
    "\n",
    "HTTP is the set of rules to allow browsers to retrieve web documents from servers over the Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocol\n",
    "A set of rules that all parties follow so we can predict each other's behavior, and not bump into each other, example drive on the right-hand side of the road"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.dr-chuck.com/page1.htm\n",
    "\n",
    "* protocol: http://\n",
    "* host: www.dr-chuck.com\n",
    "* document /page1.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data from the server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time that a user clicks to swith to a new page, the browser makes a connection to the web server and issues a \"GET\" request to get the content of the page at the specified URL.\n",
    "\n",
    "The server returns the HTML document to the browser wich formats and displays the document to the user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a HTTP request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a Web Browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 400 Bad Request\n",
      "Date: Sun, 12 Jun 2022 05:27:49 GMT\n",
      "Server: Apache/2.4.18 (Ubuntu)\n",
      "Content-Length: 308\n",
      "Connection: close\n",
      "Content-Type: text/html; charset=iso-8859-1\n",
      "\n",
      "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n",
      "<html><head>\n",
      "<title>400 Bad Request</title>\n",
      "</head><body>\n",
      "<h1>Bad Request</h1>\n",
      "<p>Your browser sent a request that this server could not understand.<br />\n",
      "</p>\n",
      "<hr>\n",
      "<address>Apache/2.4.18 (Ubuntu) Server at do1.dr-chuck.com Port 80</address>\n",
      "</body></html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80))\n",
    "# GET request\n",
    "cmd = 'GET http://data.pr4e.org/romeo.txt HTTP/1.0\\n\\n'.encode()\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(512)\n",
    "    if (len(data) < 1):\n",
    "        break\n",
    "    print(data.decode())\n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 200 OK\n",
      "Date: Sun, 12 Jun 2022 05:27:35 GMT\n",
      "Server: Apache/2.4.18 (Ubuntu)\n",
      "Last-Modified: Sat, 13 May 2017 11:22:22 GMT\n",
      "ETag: \"a7-54f6609245537\"\n",
      "Accept-Ranges: bytes\n",
      "Content-Length: 167\n",
      "Cache-Control: max-age=0, no-cache, no-store, must-revalidate\n",
      "Pragma: no-cache\n",
      "Expires: Wed, 11 Jan 1984 05:00:00 GMT\n",
      "Connection: close\n",
      "Content-Type: text/plain\n",
      "\n",
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "# This is a simple web browser\n",
    "\n",
    "import socket\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80))\n",
    "cmd = 'GET http://data.pr4e.org/romeo.txt HTTP/1.0\\r\\n\\r\\n'.encode()\n",
    "mysock.send(cmd)\n",
    "\n",
    "while True:\n",
    "    data = mysock.recv(512)\n",
    "    if len(data) < 1:\n",
    "        break\n",
    "    print(data.decode(),end='')\n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing\n",
    "### About characters and strings\n",
    "The most common in the west is ASCII, it have 8 bits\n",
    "\n",
    "* The ord() funtion tells us the numeric value of a simple ASCII character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "101\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(ord('H'))\n",
    "print(ord('e'))\n",
    "print(ord('\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But ascii do not cover all the characters. That is the reason of other standard as UNICODE, the most extenden is:\n",
    "* UTF-8 that have 1-4 bytes, it's recommended practice for encoding data to be exchanged between systems\n",
    "\n",
    "In python 3 all strings are unicode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When e talk to an external resorce like a network socket we sends bytes, so we need to encode Python3 strings into a given character encoding\n",
    "* When we read data from an external resource, we must decode it based on the character set so it is properly represented in Python3 as a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![socket](images/socket.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making HTTP Easier with urllib\n",
    "### Using urllib in Python\n",
    "Is a library that does all the socket work for us and makes web pages look like a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, urllib.parse, urllib.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "for line in fhand:\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'But': 1, 'soft': 1, 'what': 1, 'light': 1, 'through': 1, 'yonder': 1, 'window': 1, 'breaks': 1, 'It': 1, 'is': 3, 'the': 3, 'east': 1, 'and': 3, 'Juliet': 1, 'sun': 2, 'Arise': 1, 'fair': 1, 'kill': 1, 'envious': 1, 'moon': 1, 'Who': 1, 'already': 1, 'sick': 1, 'pale': 1, 'with': 1, 'grief': 1}\n"
     ]
    }
   ],
   "source": [
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "counts = dict()\n",
    "for line in fhand:\n",
    "    words = line.decode().split()\n",
    "    for word in words:\n",
    "        counts[word] = counts.get(word, 0) + 1\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Web Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>The First Page</h1>\n",
      "<p>\n",
      "If you like, you can switch to the\n",
      "<a href=\"http://www.dr-chuck.com/page2.htm\">\n",
      "Second Page</a>.\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "fhand = urllib.request.urlopen('http://www.dr-chuck.com/page1.htm')\n",
    "for line in fhand:\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing HTML - Web Scraping\n",
    "* When a program or script pretends to be a browser and retrieves web pages, looks at those web pages, extracts information, and then looks at more web pages\n",
    "* Search engines scrape web pages - we call this \"spidering the web\" or \"web crawling\"\n",
    "\n",
    "### Why Scrape?\n",
    "* Pull data- particularly social data - who links to who?\n",
    "* Get your own data back out of some system that has no \"export capability\"\n",
    "* Monitor a site for new information\n",
    "* Spider the web to make a database for search engine\n",
    "\n",
    "### Scraping web pages\n",
    "* There is som controversy about web pages scraping and some sites are a bit snippy about it\n",
    "* Republishing copyrighted information is not allowed\n",
    "* Violating terms of service is not allowed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Easy Way - Beautiful Soup\n",
    "* You could do string searches the hard way or use the library Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.dr-chuck.com/page2.htm\n"
     ]
    }
   ],
   "source": [
    "# url = http://www.dr-chuck.com/page1.htm\n",
    "url = input('Enter -')\n",
    "html = urllib.request.urlopen(url).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('a')\n",
    "for tag in tags:\n",
    "    print(tag.get('href', None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "* The TCP/IP gives us pipes / sockets between applications\n",
    "* We desinged application protocols to make use of these pipes\n",
    "* HTTP is a simple yet powerful protocol\n",
    "* Python has good support for sockets, HTTP and HTML parsing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('DS4A-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f83222598422434fc400a8455b5c5dcc255e92c9440a203626fed095cefc0f12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
